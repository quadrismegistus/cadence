{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')\n",
    "from cadence.imports import *\n",
    "import cadence as cd\n",
    "import lltk\n",
    "C=lltk.load('TedJDH')\n",
    "t=random.choice([t for t in C.texts() if t.medium=='Fiction'])\n",
    "line=random.choice([\n",
    "    ln for ln in t.txt.split('\\n') if ln.strip() and len(ln)>20\n",
    "])#.split(',')[0]\n",
    "# t,line\n",
    "# line= 'finding that he had ample time, sat down'\n",
    "#line='mercy and justice chained into the unborn world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process(q, iolock):\n",
    "#     from time import sleep\n",
    "#     while True:\n",
    "#         stuff = q.get()\n",
    "#         if stuff is None:\n",
    "#             break\n",
    "#         with iolock:\n",
    "#             print(\"processing\", stuff)\n",
    "#         sleep(stuff)\n",
    "\n",
    "# NCORE=2\n",
    "# q = mp.Queue(maxsize=NCORE)\n",
    "# iolock = mp.Lock()\n",
    "# pool = mp.Pool(NCORE, initializer=process, initargs=(q, iolock))\n",
    "# for stuff in range(20):\n",
    "#     q.put(stuff)  # blocks until q below its max size\n",
    "#     with iolock:\n",
    "#         print(\"queued\", stuff)\n",
    "# for _ in range(NCORE):  # tell workers we're done\n",
    "#     q.put(None)\n",
    "# pool.close()\n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt=\"\"\"In Xanadu did Kubla Khan\n",
    "# A stately pleasure-dome decree:\n",
    "# Where Alph, the sacred river, ran\n",
    "# Through caverns measureless to man\n",
    "#    Down to a sunless sea.\n",
    "# \"\"\"\n",
    "# line=txt.split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTALCOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = C.texts(C.meta.query('medium==\"Poetry\"'))\n",
    "# poemss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jones, Henry, 1721-1770, _VERSES TO HIS GRACE THE DUKE OF NEWCASTLE ON THE DEATH OF THE RIGHT HONOURABLE HENRY PELHAM._ (1754) [TedJDH: K046497.000]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnow=C.textd['K046497.000']\n",
    "tnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over line scansions [x1]:  55%|█████▍    | 148/271 [00:13<00:08, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over line scansions [x1]:  60%|█████▉    | 162/271 [00:15<00:08, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 68.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 90.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 91.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 114.86it/s]\n",
      "Iterating over line scansions [x1]:  81%|████████  | 220/271 [00:21<00:15,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 100.52it/s]\n",
      "Iterating over line scansions [x1]:  82%|████████▏ | 221/271 [00:22<00:15,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 50.80it/s]\n",
      "Iterating over line scansions [x1]:  82%|████████▏ | 222/271 [00:22<00:16,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]:  50%|█████     | 2/4 [00:00<00:00, 19.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 4/4 [00:00<00:00, 19.52it/s]\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 104.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 83.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 37.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 99.13it/s]\n",
      "Iterating over line scansions [x1]:  84%|████████▍ | 227/271 [00:24<00:17,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 75.69it/s]\n",
      "Iterating over line scansions [x1]:  84%|████████▍ | 228/271 [00:25<00:16,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 36.65it/s]\n",
      "Iterating over line scansions [x1]:  85%|████████▍ | 229/271 [00:25<00:15,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 101.66it/s]\n",
      "Iterating over line scansions [x1]:  85%|████████▍ | 230/271 [00:25<00:13,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 56.96it/s]\n",
      "Iterating over line scansions [x1]:  85%|████████▌ | 231/271 [00:26<00:14,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 4/4 [00:00<00:00, 42.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 2/2 [00:00<00:00, 81.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 2/2 [00:00<00:00, 74.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 94.63it/s]\n",
      "Iterating over line scansions [x1]:  87%|████████▋ | 235/271 [00:28<00:14,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 2/2 [00:00<00:00, 75.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 2/2 [00:00<00:00, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 72.94it/s]\n",
      "Iterating over line scansions [x1]:  88%|████████▊ | 238/271 [00:29<00:12,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 83.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 85.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 57.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 2/2 [00:00<00:00, 61.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 2/2 [00:00<00:00, 86.56it/s]\n",
      "Iterating over line scansions [x1]:  90%|████████▉ | 243/271 [00:31<00:10,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 103.09it/s]\n",
      "Iterating over line scansions [x1]:  90%|█████████ | 244/271 [00:31<00:10,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 92.70it/s]\n",
      "Iterating over line scansions [x1]:  90%|█████████ | 245/271 [00:32<00:10,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 95.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 83.23it/s]\n",
      "Iterating over line scansions [x1]:  91%|█████████ | 247/271 [00:32<00:09,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 49.98it/s]\n",
      "Iterating over line scansions [x1]:  92%|█████████▏| 248/271 [00:33<00:09,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 4/4 [00:00<00:00, 88.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 93.31it/s]\n",
      "Iterating over line scansions [x1]:  92%|█████████▏| 250/271 [00:34<00:08,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 63.71it/s]\n",
      "Iterating over line scansions [x1]:  93%|█████████▎| 251/271 [00:34<00:07,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 51.68it/s]\n",
      "Iterating over line scansions [x1]:  93%|█████████▎| 252/271 [00:34<00:06,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 67.09it/s]\n",
      "Iterating over line scansions [x1]:  93%|█████████▎| 253/271 [00:35<00:06,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 67.53it/s]\n",
      "Iterating over line scansions [x1]:  94%|█████████▎| 254/271 [00:35<00:05,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 66.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 60.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 2/2 [00:00<00:00, 79.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 89.32it/s]\n",
      "Iterating over line scansions [x1]:  95%|█████████▌| 258/271 [00:36<00:04,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 2/2 [00:00<00:00, 62.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 2/2 [00:00<00:00, 74.38it/s]\n",
      "Iterating over line scansions [x1]:  96%|█████████▌| 260/271 [00:37<00:04,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 81.36it/s]\n",
      "Iterating over line scansions [x1]:  96%|█████████▋| 261/271 [00:38<00:04,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 2/2 [00:00<00:00, 42.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 75.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 73.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 32.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 103.38it/s]\n",
      "Iterating over line scansions [x1]:  98%|█████████▊| 266/271 [00:40<00:01,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 92.52it/s]\n",
      "Iterating over line scansions [x1]:  99%|█████████▊| 267/271 [00:40<00:01,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 97.70it/s]\n",
      "Iterating over line scansions [x1]:  99%|█████████▉| 268/271 [00:41<00:01,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 98.17it/s]\n",
      "Iterating over line scansions [x1]:  99%|█████████▉| 269/271 [00:41<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 69.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrically parsing lines (+word IPA combinations) [x1]: 100%|██████████| 1/1 [00:00<00:00, 70.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iterating over line scansions [x1]: 100%|██████████| 271/271 [00:42<00:00,  6.41it/s]\n"
     ]
    }
   ],
   "source": [
    "tparsed=cd.parse(\n",
    "    tnow.txt,\n",
    "    verse=True,\n",
    "    by_line=True,\n",
    "    only_best=True,\n",
    "    num_proc=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'UndefinedVariableError'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-24069d797d2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedVariableError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'UndefinedVariableError'"
     ]
    }
   ],
   "source": [
    "pd.UndefinedVariableError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over line scansions [x1]:   3%|▎         | 8/271 [00:03<01:56,  2.26it/s]"
     ]
    },
    {
     "ename": "SpecificationError",
     "evalue": "Column(s) ['combo_num_syll', 'parse_num_pos', 'parse_num_syll'] do not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSpecificationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f4f07fd1fc8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     tparsed=cd.parse(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/cadence/cadence/parsers/metrics.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(txt_or_txtdf, *x, **y)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mparses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \"\"\"\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_or_txtdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/cadence/cadence/parsers/metrics.py\u001b[0m in \u001b[0;36mparse_iter\u001b[0;34m(txt_or_txtdf, by_line, by_syll, only_best, num_proc, progress, force, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mby_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby_syll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mby_syll\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby_line\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     yield from iter_parsed_lines(\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mtxt_or_txtdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/cadence/cadence/parsers/metrics.py\u001b[0m in \u001b[0;36miter_parsed_lines\u001b[0;34m(txt_or_txtdf, num_proc, progress, by_line, only_best, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mby_line\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     )\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterr2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0monly_best\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/cadence/cadence/parsers/metrics.py\u001b[0m in \u001b[0;36miter_combos_as_lines\u001b[0;34m(parsed_line_iter, by_line)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdfline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed_line_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mby_line\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mto_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0msort_by_total_and_syll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/cadence/cadence/parsers/metrics.py\u001b[0m in \u001b[0;36mto_lines\u001b[0;34m(parses, totalcol, rankcol, agg)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0mlgby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stanza_i'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'line_i'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'linepart_i'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m     \u001b[0mlinesums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresetindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrparses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinesums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_mangle_lambdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/aggregation.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(obj, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAggFuncTypeDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0magg_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# we require a list, but not an 'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/aggregation.py\u001b[0m in \u001b[0;36magg_dict_like\u001b[0;34m(obj, arg, _axis)\u001b[0m\n\u001b[1;32m    756\u001b[0m         ) != len(keys):\n\u001b[1;32m    757\u001b[0m             \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mSpecificationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column(s) {cols} do not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSpecificationError\u001b[0m: Column(s) ['combo_num_syll', 'parse_num_pos', 'parse_num_syll'] do not exist"
     ]
    }
   ],
   "source": [
    "random.shuffle(poems)\n",
    "for t in poems:\n",
    "    tparsed=cd.parse(\n",
    "        t.txt,\n",
    "        verse=True,\n",
    "        by_line=True,\n",
    "        only_best=True\n",
    "    )\n",
    "    \n",
    "#     for linedf in cd.parse_iter(\n",
    "#             t.txt,\n",
    "#             verse=True,\n",
    "#             by_line=True,\n",
    "#             only_best=False):\n",
    "#         pass\n",
    "    break\n",
    "tparsed\n",
    "\n",
    "# cd.parse(line,num_proc=1,by_line=True,only_best=True,force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm /home/ryan/.cadence/data/db.lines.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSELINEKEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in cd.scan(txt,phrasebreaks=False,num_proc=1): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in cd.parse_iter(\n",
    "#     txt,\n",
    "#     phrasebreaks=False,\n",
    "#     num_proc=1,\n",
    "#     by_line=True): display(x)\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.parse(\n",
    "    txt,\n",
    "    phrasebreaks=False,\n",
    "    num_proc=1,\n",
    "    by_line=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_num_lines??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh /home/ryan/.cadence/data/db.lines.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lltk\n",
    "C=lltk.load('CanonFiction')\n",
    "txt_long=C.au.Joyce.Ulysses.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%timeit\n",
    "# for x in scan_iter(txt_long,verse=False): pass\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltrh ~/.cadence/data\n",
    "# !mvln /home/ryan/.cadence /home/ryan/subspace/.cadence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(txt_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in cd.parse_iter(\n",
    "#     txt_long,\n",
    "#     prose=True,\n",
    "#     num_proc=4,\n",
    "#     by_line=True):\n",
    "#         #display(x)\n",
    "#         #break\n",
    "#         pass\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linedf in cd.scan_iter(txt): break\n",
    "len(linedf.drop_duplicates(['word_i','syll_i']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfparses=cd.parse(txt_long[:10000], prose=True, by_line=True)\n",
    "dfbestparses=dfparses.query('parse_rank==1')\n",
    "dfbestparses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbestparses.shape, dfparses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbestparses_pentameter = dfbestparses.query('parse_num_syll==10')\n",
    "dfbestparses_pentameter.sort_values('*total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sby=['stanza_i','line_i','linepart_i']\n",
    "# dfparses_nocombo = dfparses.reset_index().sort_values(\n",
    "#     sby+['*total']\n",
    "# ).drop_duplicates(\n",
    "#     sby,\n",
    "#     keep='first'\n",
    "# )\n",
    "# setindex(dfparses_nocombo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfparses_nocombo.query('parse_num_syll==10').sort_values('*total',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfparses.query(\n",
    "    'parse_num_syll==10'\n",
    ")sort_values('*total',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -la ~ | grep .cadence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linedf in cd.scan_iter(txt_long,num_proc=1): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in iter_parses(txt_long,progress=False,num_proc=1): pass\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linedf in cd.scan_iter(txt_long,num_proc=4): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.iter_combos??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfscan=scan(txt_long,num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.iter_lines??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combodf in iter_combos(scan(line)): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf=parse(line,num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lltk\n",
    "C=lltk.load('CanonFiction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfparses=parse(C.au.Joyce.Ulysses.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_combo(combodf).reset_index()[pcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_prosodic(combodf) == "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for combodf in iter_combos(scan(line)): pass\n",
    "combo_cols=set(combodf.reset_index().columns)\n",
    "combo_cols\n",
    "combodf_parsed=parse_combo(combodf).reset_index()\n",
    "cols_weneed = [c for c in combodf_parsed.columns if c not in combo_cols]\n",
    "combodf_parsed[cols_weneed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_parsed_pros = parse_prosodic(combodf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combodf_parsed.reset_index()[cols_weneed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_weneed=set(parse_cols) - set(combo_cols)\n",
    "cols_weneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=parse_prosodic('Bird bird bird bird', constraints=['*w/peak','*w/stressed','*s/unstressed','*f-res'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs=l.bestParse()\n",
    "pos=prs.positions[0]\n",
    "prs.constraintScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for posx in prs.positions: print(posx.constraintScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.config['meters']['default_english'].constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.Meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_phons():\n",
    "    output_dict['[*clash_across]']=counts(stress_str,'P#P') + counts(stress_str,'P#S') + counts(stress_str,'S#P') + counts(stress_str,'S#S')\n",
    "    output_dict['[*clash_within]']=counts(stress_str,'PP') + counts(stress_str,'PS') + counts(stress_str,'SP') + counts(stress_str,'SS')\n",
    "    output_dict['[*clash_across_primary]']=counts(stress_str,'P#P')\n",
    "    output_dict['[*clash_within_primary]']=counts(stress_str,'PP')\n",
    "    output_dict['[*lapse_across]']=counts(stress_str,'U#U')\n",
    "    output_dict['[*lapse_within]']=counts(stress_str,'UU')\n",
    "    output_dict['[*WSP]']=0\n",
    "    output_dict['[*PEAKPROM]']=0\n",
    "    output_dict['[*High_Stress]']=0\n",
    "    output_dict['[*Low_Unstress]']=0\n",
    "    output_dict['[*High_Strong]']=0\n",
    "    output_dict['[*Low_Weak]']=0\n",
    "    for s,w,hml,mtr in zip(stress_str,weight_str,sonority_str,meter_str):\n",
    "        if s=='U' and w=='H':\n",
    "            output_dict['[*WSP]']+=1\n",
    "        if (s=='P' or s=='S') and w=='L':\n",
    "            output_dict['[*PEAKPROM]']+=1\n",
    "        \n",
    "        if hml=='H' and s in {'P','S'}:\n",
    "            output_dict['[*High_Stress]']+=1\n",
    "        if hml=='L' and s==\"U\":\n",
    "            output_dict['[*Low_Unstress]']+=1\n",
    "        \n",
    "        if hml=='H' and mtr == 's':\n",
    "            output_dict['[*High_Strong]']+=1\n",
    "        if hml=='L' and mtr == 'w':\n",
    "            output_dict['[*Low_Weak]']+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
